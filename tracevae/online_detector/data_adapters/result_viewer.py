#!/usr/bin/env python3
"""
æ£€æµ‹ç»“æœæŸ¥çœ‹å™¨ - åˆ†æå’Œå¯è§†åŒ–å¼‚å¸¸æ£€æµ‹ç»“æœ
"""

import json
import pandas as pd
from pathlib import Path
from datetime import datetime
import matplotlib.pyplot as plt
import seaborn as sns
from typing import List, Dict
import logging

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class DetectionResultViewer:
    """æ£€æµ‹ç»“æœæŸ¥çœ‹å™¨"""
    
    def __init__(self, result_file: str):
        self.result_file = Path(result_file)
        self.results = self.load_results()
    
    def load_results(self) -> List[Dict]:
        """åŠ è½½æ£€æµ‹ç»“æœ"""
        try:
            with open(self.result_file, 'r', encoding='utf-8') as f:
                results = json.load(f)
            logger.info(f"âœ… åŠ è½½äº† {len(results)} ä¸ªæ£€æµ‹ç»“æœ")
            return results
        except Exception as e:
            logger.error(f"âŒ åŠ è½½ç»“æœæ–‡ä»¶å¤±è´¥: {e}")
            return []
    
    def show_summary(self):
        """æ˜¾ç¤ºæ£€æµ‹ç»“æœæ‘˜è¦"""
        if not self.results:
            print("âŒ æ²¡æœ‰æ£€æµ‹ç»“æœ")
            return
        
        total_traces = len(self.results)
        anomaly_traces = sum(1 for r in self.results if r.get('is_anomaly', False))
        normal_traces = total_traces - anomaly_traces
        
        # è®¡ç®—å¹³å‡ç½®ä¿¡åº¦
        avg_confidence = sum(r.get('confidence', 0) for r in self.results) / total_traces
        avg_processing_time = sum(r.get('processing_time_ms', 0) for r in self.results) / total_traces
        
        print("\n" + "="*60)
        print(f"ğŸ“Š æ£€æµ‹ç»“æœæ‘˜è¦ - {self.result_file.name}")
        print("="*60)
        print(f"ğŸ“ˆ æ€»traceæ•°é‡: {total_traces}")
        print(f"âœ… æ­£å¸¸traces: {normal_traces} ({normal_traces/total_traces*100:.1f}%)")
        print(f"ğŸš¨ å¼‚å¸¸traces: {anomaly_traces} ({anomaly_traces/total_traces*100:.1f}%)")
        print(f"ğŸ¯ å¹³å‡ç½®ä¿¡åº¦: {avg_confidence:.3f}")
        print(f"â±ï¸  å¹³å‡å¤„ç†æ—¶é—´: {avg_processing_time:.1f}ms")
        
        # å¼‚å¸¸ç±»å‹ç»Ÿè®¡
        anomaly_types = {}
        for result in self.results:
            if result.get('is_anomaly', False):
                anomaly_type = result.get('anomaly_type', 'unknown')
                anomaly_types[anomaly_type] = anomaly_types.get(anomaly_type, 0) + 1
        
        if anomaly_types:
            print(f"\nğŸ·ï¸  å¼‚å¸¸ç±»å‹åˆ†å¸ƒ:")
            for anomaly_type, count in sorted(anomaly_types.items()):
                percentage = count / anomaly_traces * 100 if anomaly_traces > 0 else 0
                print(f"  - {anomaly_type}: {count} ({percentage:.1f}%)")
    
    def show_anomalies(self, limit: int = 10):
        """æ˜¾ç¤ºå¼‚å¸¸è¯¦æƒ…"""
        anomalies = [r for r in self.results if r.get('is_anomaly', False)]
        
        if not anomalies:
            print("\nğŸ‰ æ­å–œï¼æ²¡æœ‰æ£€æµ‹åˆ°ä»»ä½•å¼‚å¸¸")
            return
        
        print(f"\nğŸš¨ æ£€æµ‹åˆ°çš„å¼‚å¸¸ (å‰{min(limit, len(anomalies))}ä¸ª):")
        print("-" * 80)
        
        # æŒ‰ç½®ä¿¡åº¦æ’åº
        anomalies_sorted = sorted(anomalies, key=lambda x: x.get('confidence', 0), reverse=True)
        
        for i, anomaly in enumerate(anomalies_sorted[:limit], 1):
            trace_id = anomaly.get('traceID', 'N/A')
            anomaly_type = anomaly.get('anomaly_type', 'unknown')
            confidence = anomaly.get('confidence', 0)
            
            details = anomaly.get('details', {})
            latency_score = details.get('nodeLatencyScore', 0)
            structure_score = details.get('graphStructureScore', 0)
            
            print(f"\n{i}. TraceID: {trace_id}")
            print(f"   å¼‚å¸¸ç±»å‹: {anomaly_type}")
            print(f"   ç½®ä¿¡åº¦: {confidence:.3f}")
            print(f"   å»¶è¿Ÿåˆ†æ•°: {latency_score:.3f}")
            print(f"   ç»“æ„åˆ†æ•°: {structure_score:.3f}")
            
            # å¦‚æœæœ‰spansä¿¡æ¯ï¼Œæ˜¾ç¤ºé—®é¢˜spans
            if 'spans' in anomaly:
                spans = anomaly['spans']
                print(f"   Spansæ•°é‡: {len(spans)}")
                
                # æ‰¾å‡ºæœ€å¯èƒ½æœ‰é—®é¢˜çš„span
                if spans and isinstance(spans, list):
                    max_duration_span = max(spans, key=lambda s: s.get('duration', 0))
                    duration_ms = max_duration_span.get('duration', 0) / 1000
                    print(f"   æœ€é•¿è€—æ—¶Span: {max_duration_span.get('operationName', 'N/A')} ({duration_ms:.1f}ms)")
    
    def show_normal_traces(self, limit: int = 5):
        """æ˜¾ç¤ºæ­£å¸¸tracesæ ·ä¾‹"""
        normal_traces = [r for r in self.results if not r.get('is_anomaly', False)]
        
        if not normal_traces:
            print("\nâš ï¸  æ²¡æœ‰æ­£å¸¸çš„traces")
            return
        
        print(f"\nâœ… æ­£å¸¸tracesæ ·ä¾‹ (å‰{min(limit, len(normal_traces))}ä¸ª):")
        print("-" * 60)
        
        for i, trace in enumerate(normal_traces[:limit], 1):
            trace_id = trace.get('traceID', 'N/A')
            confidence = trace.get('confidence', 0)
            processing_time = trace.get('processing_time_ms', 0)
            
            print(f"{i}. TraceID: {trace_id}")
            print(f"   ç½®ä¿¡åº¦: {confidence:.3f}")
            print(f"   å¤„ç†æ—¶é—´: {processing_time:.1f}ms")
    
    def export_to_csv(self, output_file: str = None):
        """å¯¼å‡ºç»“æœåˆ°CSV"""
        if not self.results:
            print("âŒ æ²¡æœ‰æ•°æ®å¯å¯¼å‡º")
            return
        
        if not output_file:
            output_file = f"analysis_{self.result_file.stem}.csv"
        
        # å‡†å¤‡æ•°æ®
        data = []
        for result in self.results:
            row = {
                'traceID': result.get('traceID', ''),
                'is_anomaly': result.get('is_anomaly', False),
                'anomaly_type': result.get('anomaly_type', 'normal'),
                'confidence': result.get('confidence', 0),
                'processing_time_ms': result.get('processing_time_ms', 0),
                'nodeLatencyScore': result.get('details', {}).get('nodeLatencyScore', 0),
                'graphStructureScore': result.get('details', {}).get('graphStructureScore', 0)
            }
            data.append(row)
        
        # ä¿å­˜CSV
        df = pd.DataFrame(data)
        df.to_csv(output_file, index=False)
        print(f"ğŸ“Š ç»“æœå·²å¯¼å‡ºåˆ°: {output_file}")
        
        # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
        print(f"\nğŸ“ˆ å¯¼å‡ºç»Ÿè®¡:")
        print(f"  - æ€»è®°å½•æ•°: {len(df)}")
        print(f"  - å¼‚å¸¸è®°å½•: {df['is_anomaly'].sum()}")
        print(f"  - å¹³å‡ç½®ä¿¡åº¦: {df['confidence'].mean():.3f}")
        print(f"  - æœ€é«˜ç½®ä¿¡åº¦: {df['confidence'].max():.3f}")
        print(f"  - æœ€ä½ç½®ä¿¡åº¦: {df['confidence'].min():.3f}")
    
    def create_visualization(self):
        """åˆ›å»ºå¯è§†åŒ–å›¾è¡¨"""
        if not self.results:
            print("âŒ æ²¡æœ‰æ•°æ®å¯è§†åŒ–")
            return
        
        try:
            import matplotlib.pyplot as plt
            import seaborn as sns
            
            # å‡†å¤‡æ•°æ®
            df = pd.DataFrame(self.results)
            
            # åˆ›å»ºå›¾è¡¨
            fig, axes = plt.subplots(2, 2, figsize=(15, 10))
            fig.suptitle(f'å¼‚å¸¸æ£€æµ‹ç»“æœåˆ†æ - {self.result_file.name}', fontsize=16)
            
            # 1. å¼‚å¸¸vsæ­£å¸¸åˆ†å¸ƒ
            anomaly_counts = df['is_anomaly'].value_counts()
            axes[0, 0].pie(anomaly_counts.values, labels=['æ­£å¸¸', 'å¼‚å¸¸'], autopct='%1.1f%%', 
                          colors=['lightgreen', 'lightcoral'])
            axes[0, 0].set_title('å¼‚å¸¸vsæ­£å¸¸åˆ†å¸ƒ')
            
            # 2. ç½®ä¿¡åº¦åˆ†å¸ƒ
            axes[0, 1].hist(df['confidence'], bins=20, alpha=0.7, color='skyblue', edgecolor='black')
            axes[0, 1].set_title('ç½®ä¿¡åº¦åˆ†å¸ƒ')
            axes[0, 1].set_xlabel('ç½®ä¿¡åº¦')
            axes[0, 1].set_ylabel('é¢‘æ¬¡')
            
            # 3. å¼‚å¸¸ç±»å‹åˆ†å¸ƒ
            if 'anomaly_type' in df.columns:
                anomaly_types = df[df['is_anomaly'] == True]['anomaly_type'].value_counts()
                if len(anomaly_types) > 0:
                    axes[1, 0].bar(anomaly_types.index, anomaly_types.values, color='orange')
                    axes[1, 0].set_title('å¼‚å¸¸ç±»å‹åˆ†å¸ƒ')
                    axes[1, 0].set_xlabel('å¼‚å¸¸ç±»å‹')
                    axes[1, 0].set_ylabel('æ•°é‡')
                    plt.setp(axes[1, 0].xaxis.get_majorticklabels(), rotation=45)
            
            # 4. å¤„ç†æ—¶é—´åˆ†å¸ƒ
            if 'processing_time_ms' in df.columns:
                axes[1, 1].hist(df['processing_time_ms'], bins=20, alpha=0.7, color='lightcyan', edgecolor='black')
                axes[1, 1].set_title('å¤„ç†æ—¶é—´åˆ†å¸ƒ')
                axes[1, 1].set_xlabel('å¤„ç†æ—¶é—´ (ms)')
                axes[1, 1].set_ylabel('é¢‘æ¬¡')
            
            plt.tight_layout()
            
            # ä¿å­˜å›¾è¡¨
            chart_file = f"analysis_chart_{self.result_file.stem}.png"
            plt.savefig(chart_file, dpi=300, bbox_inches='tight')
            print(f"ğŸ“ˆ å¯è§†åŒ–å›¾è¡¨å·²ä¿å­˜åˆ°: {chart_file}")
            
            # æ˜¾ç¤ºå›¾è¡¨
            plt.show()
            
        except ImportError:
            print("âš ï¸  éœ€è¦å®‰è£…matplotlibå’Œseaborn: pip install matplotlib seaborn")
        except Exception as e:
            print(f"âŒ åˆ›å»ºå¯è§†åŒ–å¤±è´¥: {e}")

def main():
    """ä¸»å‡½æ•°"""
    import argparse
    
    parser = argparse.ArgumentParser(description="æ£€æµ‹ç»“æœæŸ¥çœ‹å™¨")
    parser.add_argument("result_file", help="æ£€æµ‹ç»“æœJSONæ–‡ä»¶è·¯å¾„")
    parser.add_argument("--export-csv", action="store_true", help="å¯¼å‡ºåˆ°CSVæ–‡ä»¶")
    parser.add_argument("--visualize", action="store_true", help="åˆ›å»ºå¯è§†åŒ–å›¾è¡¨")
    parser.add_argument("--anomaly-limit", type=int, default=10, help="æ˜¾ç¤ºå¼‚å¸¸çš„æ•°é‡é™åˆ¶")
    
    args = parser.parse_args()
    
    # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if not Path(args.result_file).exists():
        print(f"âŒ ç»“æœæ–‡ä»¶ä¸å­˜åœ¨: {args.result_file}")
        return
    
    # åˆ›å»ºæŸ¥çœ‹å™¨
    viewer = DetectionResultViewer(args.result_file)
    
    # æ˜¾ç¤ºæ‘˜è¦
    viewer.show_summary()
    
    # æ˜¾ç¤ºå¼‚å¸¸è¯¦æƒ…
    viewer.show_anomalies(args.anomaly_limit)
    
    # æ˜¾ç¤ºæ­£å¸¸tracesæ ·ä¾‹
    viewer.show_normal_traces(5)
    
    # å¯¼å‡ºCSV
    if args.export_csv:
        viewer.export_to_csv()
    
    # åˆ›å»ºå¯è§†åŒ–
    if args.visualize:
        viewer.create_visualization()

if __name__ == "__main__":
    main()