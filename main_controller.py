# -*- coding: utf-8 -*-
"""
Train Ticket å¼‚å¸¸æ£€æµ‹ç³»ç»Ÿä¸»æ§åˆ¶å™¨
ä¸€é”®å¯åŠ¨ï¼šå‹æµ‹ + æ•°æ®é‡‡é›† + å®æ—¶å¼‚å¸¸æ£€æµ‹

Author: LoveShikiNatsume
Date: 2025-06-18
Version: 1.0 - ç®€åŒ–ç‰ˆï¼Œé»˜è®¤å®æ—¶ç›‘æ§æ¨¡å¼
"""

import os
import sys
import time
import json
import logging
import subprocess
import threading
from datetime import datetime, timedelta
from typing import Dict, List, Optional
from pathlib import Path

# æ·»åŠ å­ç›®å½•åˆ°è·¯å¾„
sys.path.append(str(Path(__file__).parent / "train-ticket-trace-collect"))

class TrainTicketAnomalyDetectionController:
    """Train Ticket å¼‚å¸¸æ£€æµ‹ç³»ç»Ÿä¸»æ§åˆ¶å™¨ - ä¸€é”®å¯åŠ¨æ¨¡å¼"""
    
    def __init__(self):
        self.project_root = Path(__file__).parent
        self.config = self._load_default_config()
        self.logger = self._setup_logging()
        
        # å„ç»„ä»¶çš„çŠ¶æ€
        self.component_status = {
            "load_test": "æœªå¼€å§‹",
            "data_collection": "æœªå¼€å§‹",
            "anomaly_detection": "æœªå¼€å§‹"
        }
        
        # è¿è¡Œç»“æœå­˜å‚¨
        self.results = {
            "start_time": None,
            "end_time": None,
            "real_time_detections": []
        }
        
        # å®æ—¶ç›‘æ§ç›¸å…³
        self.monitoring_active = False
        self.last_processed_minute = None
        
        self.logger.info("ğŸš€ Train Ticket å¼‚å¸¸æ£€æµ‹ç³»ç»Ÿå¯åŠ¨")
        self.logger.info("ä¸€é”®å¯åŠ¨æ¨¡å¼ï¼šè‡ªåŠ¨å‹æµ‹ + æ•°æ®é‡‡é›† + å®æ—¶å¼‚å¸¸æ£€æµ‹")
        self.logger.info("æŒ‰ Ctrl+C åœæ­¢è¿è¡Œ")

    def _load_default_config(self) -> Dict:
        """åŠ è½½é»˜è®¤é…ç½®"""
        return {
            "real_time_mode": {
                "enabled": True,
                "check_interval_seconds": 30,
                "auto_process_delay_seconds": 65,
                "detection_threshold": 0.15
            },
            "data_collection": {
                "interval_seconds": 60,
                "lookback_period": "5m"
            }
        }

    def _setup_logging(self):
        """è®¾ç½®æ—¥å¿—"""
        logger = logging.getLogger('MainController')
        logger.setLevel(logging.INFO)
        
        # æ¸…é™¤ç°æœ‰å¤„ç†å™¨
        for handler in logger.handlers[:]:
            logger.removeHandler(handler)
        
        # æ§åˆ¶å°å¤„ç†å™¨
        console_handler = logging.StreamHandler()
        console_handler.setLevel(logging.INFO)
        formatter = logging.Formatter('%(asctime)s - [ä¸»æ§åˆ¶å™¨] - %(levelname)s - %(message)s')
        console_handler.setFormatter(formatter)
        logger.addHandler(console_handler)
        
        # æ–‡ä»¶å¤„ç†å™¨
        log_dir = self.project_root / "logs"
        log_dir.mkdir(exist_ok=True)
        
        file_handler = logging.FileHandler(
            log_dir / f"main_controller_{datetime.now().strftime('%Y%m%d_%H%M%S')}.log",
            encoding='utf-8'
        )
        file_handler.setLevel(logging.DEBUG)
        file_handler.setFormatter(formatter)
        logger.addHandler(file_handler)
        
        return logger

    def _run_subprocess(self, cmd: List[str], component_name: str, 
                       timeout: Optional[int] = None, 
                       background: bool = False) -> subprocess.Popen:
        """è¿è¡Œå­è¿›ç¨‹"""
        self.logger.info(f"å¯åŠ¨ {component_name}")
        
        try:
            if background:
                # åå°è¿è¡Œ
                process = subprocess.Popen(
                    cmd,
                    stdout=subprocess.PIPE,
                    stderr=subprocess.PIPE,
                    text=True,
                    cwd=self.project_root
                )
                self.component_status[component_name.lower().replace(' ', '_')] = "è¿è¡Œä¸­"
                return process
            else:
                # å‰å°è¿è¡Œå¹¶ç­‰å¾…å®Œæˆ
                result = subprocess.run(
                    cmd,
                    capture_output=True,
                    text=True,
                    timeout=timeout,
                    cwd=self.project_root
                )
                
                if result.returncode == 0:
                    self.logger.info(f"{component_name} æ‰§è¡ŒæˆåŠŸ")
                    self.component_status[component_name.lower().replace(' ', '_')] = "å®Œæˆ"
                else:
                    self.logger.error(f"{component_name} æ‰§è¡Œå¤±è´¥: {result.stderr}")
                    self.component_status[component_name.lower().replace(' ', '_')] = "å¤±è´¥"
                
                return result
                
        except subprocess.TimeoutExpired:
            self.logger.error(f"{component_name} æ‰§è¡Œè¶…æ—¶")
            self.component_status[component_name.lower().replace(' ', '_')] = "è¶…æ—¶"
        except Exception as e:
            self.logger.error(f"{component_name} æ‰§è¡Œå¼‚å¸¸: {e}")
            self.component_status[component_name.lower().replace(' ', '_')] = "å¼‚å¸¸"

    def start_load_test(self) -> Optional[subprocess.Popen]:
        """å¯åŠ¨å‹æµ‹ï¼ˆæ¨¡æ‹Ÿï¼‰"""
        self.logger.info("å¯åŠ¨å‹æµ‹æ¨¡æ‹Ÿå™¨...")
        
        cmd = [
            sys.executable, "-c", 
            f"""
import time
import random
print("ğŸ”„ å‹æµ‹å¼€å§‹è¿è¡Œ...")
count = 0
while True:
    count += 1
    if count % 10 == 0:
        print(f"å‹æµ‹è¿›è¡Œä¸­... å·²è¿è¡Œ {{count//10}} åˆ†é’Ÿ")
    time.sleep(30)
            """
        ]
        
        return self._run_subprocess(cmd, "load_test", background=True)

    def start_data_collection(self, duration_minutes: int = 0) -> subprocess.Popen:
        """å¯åŠ¨æ•°æ®é‡‡é›†"""
        collector_script = self.project_root / "train-ticket-trace-collect" / "trace_collector.py"
        
        cmd = [
            sys.executable, str(collector_script),
            "--duration", str(duration_minutes)
        ]
        
        return self._run_subprocess(cmd, "data_collection", background=True)

    def process_collected_data(self, target_date: str = None):
        """å¤„ç†é‡‡é›†çš„æ•°æ®ï¼ˆå›¾åˆ†æï¼‰"""
        processor_script = self.project_root / "train-ticket-trace-collect" / "graph_post_processor.py"
        
        cmd = [sys.executable, str(processor_script)]
        if target_date:
            cmd.extend(["--date", target_date])
        
        self._run_subprocess(cmd, "graph_processing", timeout=1800)

    def check_for_new_data(self, target_date: str = None) -> List[str]:
        """æ£€æŸ¥æ˜¯å¦æœ‰æ–°çš„åˆ†é’Ÿçº§æ•°æ®æ–‡ä»¶"""
        target_date = target_date or datetime.now().strftime("%Y-%m-%d")
        trace_output_dir = self.project_root / "trace_output" / target_date / "csv"
        
        if not trace_output_dir.exists():
            return []
        
        # è·å–æ‰€æœ‰CSVæ–‡ä»¶
        csv_files = list(trace_output_dir.glob("*.csv"))
        new_files = []
        
        current_time = datetime.now()
        
        for csv_file in csv_files:
            # è§£ææ–‡ä»¶å (æ ¼å¼: HH_MM.csv)
            try:
                filename = csv_file.stem
                hour, minute = filename.split('_')
                file_time = datetime.now().replace(hour=int(hour), minute=int(minute), second=0, microsecond=0)
                
                # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦æ˜¯æ–°çš„ä¸”å·²ç»"æˆç†Ÿ"ï¼ˆè¶…è¿‡65ç§’ï¼‰
                time_diff = (current_time - file_time).total_seconds()
                
                if time_diff >= self.config["real_time_mode"]["auto_process_delay_seconds"]:
                    file_key = f"{target_date}_{filename}"
                    if self.last_processed_minute is None or file_time > self.last_processed_minute:
                        new_files.append(str(csv_file))
                        self.last_processed_minute = file_time
                        
            except ValueError:
                continue
        
        return new_files

    def run_single_file_anomaly_detection(self, csv_file: str) -> Dict:
        """å¯¹å•ä¸ªCSVæ–‡ä»¶è¿è¡Œå¼‚å¸¸æ£€æµ‹ï¼ˆæ¨¡æ‹Ÿï¼‰"""
        self.logger.info(f"ğŸ” åˆ†ææ–‡ä»¶: {os.path.basename(csv_file)}")
        
        # æ¨¡æ‹Ÿå¼‚å¸¸æ£€æµ‹
        import random
        import pandas as pd
        
        try:
            # è¯»å–æ–‡ä»¶åŸºæœ¬ä¿¡æ¯
            df = pd.read_csv(csv_file)
            trace_count = len(df['traceIdLow'].unique()) if 'traceIdLow' in df.columns else 0
            span_count = len(df)
            
            # æ¨¡æ‹Ÿå¼‚å¸¸æ£€æµ‹ç»“æœ
            anomaly_score = random.uniform(0.0, 1.0)
            threshold = self.config["real_time_mode"]["detection_threshold"]
            is_anomaly = anomaly_score > threshold
            
            result = {
                "file_name": os.path.basename(csv_file),
                "analysis_time": datetime.now().isoformat(),
                "trace_count": trace_count,
                "span_count": span_count,
                "anomaly_score": round(anomaly_score, 4),
                "threshold": threshold,
                "anomaly_detected": is_anomaly,
                "anomaly_types": []
            }
            
            if is_anomaly:
                # éšæœºç”Ÿæˆå¼‚å¸¸ç±»å‹
                possible_anomalies = ["high_latency", "error_spike", "unusual_pattern", "service_degradation"]
                result["anomaly_types"] = random.sample(possible_anomalies, random.randint(1, 2))
            
            return result
            
        except Exception as e:
            self.logger.error(f"å¼‚å¸¸æ£€æµ‹å¤±è´¥: {e}")
            return {}

    def report_real_time_anomaly(self, csv_file: str, detection_result: Dict):
        """å®æ—¶å¼‚å¸¸æŠ¥å‘Š"""
        self.logger.warning("ğŸš¨ ================================")
        self.logger.warning("ğŸš¨ æ£€æµ‹åˆ°å®æ—¶å¼‚å¸¸ï¼")
        self.logger.warning("ğŸš¨ ================================")
        self.logger.warning(f"ğŸ“ æ–‡ä»¶: {detection_result['file_name']}")
        self.logger.warning(f"âš ï¸  å¼‚å¸¸åˆ†æ•°: {detection_result['anomaly_score']} (é˜ˆå€¼: {detection_result['threshold']})")
        self.logger.warning(f"ğŸ·ï¸  å¼‚å¸¸ç±»å‹: {', '.join(detection_result.get('anomaly_types', []))}")
        self.logger.warning(f"ğŸ“Š Traceæ•°é‡: {detection_result['trace_count']}")
        self.logger.warning(f"ğŸ“ˆ Spanæ•°é‡: {detection_result['span_count']}")
        self.logger.warning("ğŸš¨ ================================")
        
        # ä¿å­˜å¼‚å¸¸æŠ¥å‘Š
        anomaly_report_dir = self.project_root / "anomaly_reports"
        anomaly_report_dir.mkdir(exist_ok=True)
        
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        report_file = anomaly_report_dir / f"realtime_anomaly_{timestamp}.json"
        
        with open(report_file, 'w', encoding='utf-8') as f:
            json.dump(detection_result, f, indent=2, ensure_ascii=False)
        
        self.logger.info(f"ğŸ“‹ å¼‚å¸¸æŠ¥å‘Šå·²ä¿å­˜: {report_file}")

    def process_new_files_real_time(self, csv_files: List[str]) -> bool:
        """å®æ—¶å¤„ç†æ–°çš„CSVæ–‡ä»¶"""
        if not csv_files:
            return False
        
        self.logger.info(f"ğŸ“‹ å‘ç° {len(csv_files)} ä¸ªæ–°çš„æ•°æ®æ–‡ä»¶ï¼Œå¼€å§‹å®æ—¶å¤„ç†...")
        
        # è·å–æ—¥æœŸ
        target_date = datetime.now().strftime("%Y-%m-%d")
        date_dir = self.project_root / "trace_output" / target_date
        
        # æ£€æŸ¥æ˜¯å¦éœ€è¦å›¾åˆ†æå¤„ç†
        graph_flag = date_dir / ".graph_processed"
        need_graph_processing = not graph_flag.exists()
        
        if need_graph_processing:
            self.logger.info("ğŸ”§ é¦–æ¬¡å¤„ç†ï¼Œæ‰§è¡Œå›¾åˆ†æ...")
            self.process_collected_data(target_date)
        
        # å¯¹æ¯ä¸ªæ–°æ–‡ä»¶è¿›è¡Œå¼‚å¸¸æ£€æµ‹
        for csv_file in csv_files:
            try:
                detection_result = self.run_single_file_anomaly_detection(csv_file)
                if detection_result:
                    self.results["real_time_detections"].append({
                        "timestamp": datetime.now().isoformat(),
                        "file": os.path.basename(csv_file),
                        "result": detection_result
                    })
                    
                    # å¦‚æœæ£€æµ‹åˆ°å¼‚å¸¸ï¼Œç«‹å³æŠ¥å‘Š
                    if detection_result.get("anomaly_detected", False):
                        self.report_real_time_anomaly(csv_file, detection_result)
                    else:
                        self.logger.info(f"âœ… {os.path.basename(csv_file)} - æ­£å¸¸")
                        
            except Exception as e:
                self.logger.error(f"âŒ å¤„ç†æ–‡ä»¶ {csv_file} æ—¶å‡ºé”™: {e}")
        
        return True

    def run_real_time_monitoring(self):
        """è¿è¡Œå®æ—¶ç›‘æ§æ¨¡å¼"""
        self.logger.info("ğŸš€ å¯åŠ¨å®æ—¶å¼‚å¸¸æ£€æµ‹ç›‘æ§ç³»ç»Ÿ")
        self.logger.info("ğŸ“Š ç³»ç»Ÿå°†è‡ªåŠ¨ï¼š")
        self.logger.info("   1. å¯åŠ¨å‹æµ‹æ¨¡æ‹Ÿ")
        self.logger.info("   2. å¼€å§‹æ•°æ®é‡‡é›†")
        self.logger.info("   3. å®æ—¶å¼‚å¸¸æ£€æµ‹")
        self.logger.info("   4. å¼‚å¸¸è‡ªåŠ¨æŠ¥è­¦")
        self.logger.info("ğŸ›‘ æŒ‰ Ctrl+C åœæ­¢è¿è¡Œ")
        
        self.monitoring_active = True
        self.results["start_time"] = datetime.now().isoformat()
        
        # å¯åŠ¨å‹æµ‹ï¼ˆåå°è¿è¡Œï¼‰
        self.logger.info("ğŸ”„ å¯åŠ¨å‹æµ‹...")
        load_test_process = self.start_load_test()
        
        # å¯åŠ¨æ•°æ®é‡‡é›†ï¼ˆåå°è¿è¡Œï¼‰
        self.logger.info("ğŸ“¡ å¯åŠ¨æ•°æ®é‡‡é›†...")
        collection_process = self.start_data_collection(duration_minutes=0)
        
        # ç­‰å¾…æ•°æ®é‡‡é›†å¯åŠ¨
        self.logger.info("â³ ç­‰å¾…æ•°æ®é‡‡é›†å¯åŠ¨...")
        time.sleep(30)
        
        check_interval = self.config["real_time_mode"]["check_interval_seconds"]
        self.logger.info(f"ğŸ” å¼€å§‹å®æ—¶ç›‘æ§ (æ¯{check_interval}ç§’æ£€æŸ¥ä¸€æ¬¡æ–°æ•°æ®)")
        
        try:
            while self.monitoring_active:
                # æ£€æŸ¥æ–°æ•°æ®
                new_files = self.check_for_new_data()
                
                if new_files:
                    self.process_new_files_real_time(new_files)
                
                # æ˜¾ç¤ºè¿è¡ŒçŠ¶æ€
                elapsed_hours = (time.time() - time.mktime(datetime.fromisoformat(self.results["start_time"]).timetuple())) / 3600
                detection_count = len(self.results["real_time_detections"])
                anomaly_count = len([d for d in self.results["real_time_detections"] if d["result"].get("anomaly_detected", False)])
                
                self.logger.info(f"ğŸ“ˆ ç›‘æ§çŠ¶æ€: è¿è¡Œ{elapsed_hours:.1f}å°æ—¶ | æ£€æµ‹{detection_count}æ¬¡ | å¼‚å¸¸{anomaly_count}æ¬¡")
                
                # ç­‰å¾…ä¸‹æ¬¡æ£€æŸ¥
                time.sleep(check_interval)
                
        except KeyboardInterrupt:
            self.logger.info("ğŸ›‘ ç”¨æˆ·ä¸­æ–­ç›‘æ§")
        finally:
            self.monitoring_active = False
            
            # åœæ­¢æ‰€æœ‰åå°è¿›ç¨‹
            if load_test_process:
                self.logger.info("ğŸ›‘ åœæ­¢å‹æµ‹...")
                load_test_process.terminate()
                try:
                    load_test_process.wait(timeout=30)
                except subprocess.TimeoutExpired:
                    load_test_process.kill()
            
            if collection_process:
                self.logger.info("ğŸ›‘ åœæ­¢æ•°æ®é‡‡é›†...")
                collection_process.terminate()
                try:
                    collection_process.wait(timeout=30)
                except subprocess.TimeoutExpired:
                    collection_process.kill()
            
            self.results["end_time"] = datetime.now().isoformat()
            self.generate_final_report()

    def generate_final_report(self):
        """ç”Ÿæˆæœ€ç»ˆæŠ¥å‘Š"""
        report_dir = self.project_root / "experiment_reports"
        report_dir.mkdir(exist_ok=True)
        
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        
        detection_count = len(self.results["real_time_detections"])
        anomaly_count = len([d for d in self.results["real_time_detections"] if d["result"].get("anomaly_detected", False)])
        
        # ç”Ÿæˆç®€åŒ–æ‘˜è¦
        summary_file = report_dir / f"monitoring_summary_{timestamp}.txt"
        with open(summary_file, 'w', encoding='utf-8') as f:
            f.write("=" * 60 + "\n")
            f.write("Train Ticket å®æ—¶å¼‚å¸¸æ£€æµ‹ç›‘æ§æŠ¥å‘Š\n")
            f.write("=" * 60 + "\n\n")
            f.write(f"ç›‘æ§æ—¶é—´: {self.results['start_time']} ~ {self.results['end_time']}\n")
            f.write(f"ç›‘æ§æ—¶é•¿: {self._calculate_duration_minutes()/60:.1f} å°æ—¶\n")
            f.write(f"æ£€æµ‹æ¬¡æ•°: {detection_count}\n")
            f.write(f"å¼‚å¸¸æ¬¡æ•°: {anomaly_count}\n")
            f.write(f"å¼‚å¸¸ç‡: {(anomaly_count / max(detection_count, 1)) * 100:.1f}%\n\n")
            
            if anomaly_count > 0:
                f.write("å¼‚å¸¸æ£€æµ‹è¯¦æƒ…:\n")
                for detection in self.results["real_time_detections"]:
                    if detection["result"].get("anomaly_detected", False):
                        result = detection["result"]
                        f.write(f"  æ—¶é—´: {detection['timestamp']}\n")
                        f.write(f"  æ–‡ä»¶: {detection['file']}\n")
                        f.write(f"  å¼‚å¸¸åˆ†æ•°: {result['anomaly_score']}\n")
                        f.write(f"  å¼‚å¸¸ç±»å‹: {', '.join(result.get('anomaly_types', []))}\n")
                        f.write("\n")
        
        self.logger.info("ğŸ“‹ ====== ç›‘æ§å®Œæˆ ======")
        self.logger.info(f"ğŸ“Š æ€»è®¡æ£€æµ‹: {detection_count} æ¬¡")
        self.logger.info(f"ğŸš¨ å‘ç°å¼‚å¸¸: {anomaly_count} æ¬¡")
        self.logger.info(f"ğŸ“ ç›‘æ§æŠ¥å‘Š: {summary_file}")
        self.logger.info("ğŸ“‹ ========================")

    def _calculate_duration_minutes(self) -> float:
        """è®¡ç®—è¿è¡Œæ€»æ—¶é•¿"""
        if self.results["start_time"] and self.results["end_time"]:
            start = datetime.fromisoformat(self.results["start_time"])
            end = datetime.fromisoformat(self.results["end_time"])
            return (end - start).total_seconds() / 60
        return 0

def main():
    """ä¸»å‡½æ•° - ä¸€é”®å¯åŠ¨"""
    print("=" * 60)
    print("ğŸš€ Train Ticket å¼‚å¸¸æ£€æµ‹ç³»ç»Ÿ")
    print("=" * 60)
    print("ä¸€é”®å¯åŠ¨æ¨¡å¼ï¼šè‡ªåŠ¨è¿è¡Œæ‰€æœ‰ç»„ä»¶")
    print("åŠŸèƒ½åŒ…æ‹¬ï¼šå‹æµ‹ + æ•°æ®é‡‡é›† + å®æ—¶å¼‚å¸¸æ£€æµ‹")
    print("æŒ‰ Ctrl+C å¯éšæ—¶åœæ­¢")
    print("=" * 60)
    
    try:
        controller = TrainTicketAnomalyDetectionController()
        controller.run_real_time_monitoring()
        return 0
        
    except KeyboardInterrupt:
        print("\nğŸ›‘ ç³»ç»Ÿå·²åœæ­¢")
        return 0
    except Exception as e:
        print(f"âŒ ç³»ç»Ÿè¿è¡Œå¤±è´¥: {e}")
        return 1

if __name__ == "__main__":
    sys.exit(main())
