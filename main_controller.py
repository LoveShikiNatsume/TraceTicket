# -*- coding: utf-8 -*-
"""
Train Ticket å¼‚å¸¸æ£€æµ‹ç³»ç»Ÿä¸»æ§åˆ¶å™¨
ä¸€é”®å¯åŠ¨ï¼šå‹æµ‹ + æ•°æ®é‡‡é›† + å¼‚å¸¸æ³¨å…¥ + å®æ—¶å¼‚å¸¸æ£€æµ‹

Author: LoveShikiNatsume
Date: 2025-06-18
Version: 1.1 å®æ—¶ç›‘æ§æµç¨‹éªŒè¯
"""

import os
import sys
import time
import json
import logging
import subprocess
import threading
from datetime import datetime, timedelta
from typing import Dict, List, Optional
from pathlib import Path

# æ·»åŠ å­ç›®å½•åˆ°è·¯å¾„
sys.path.append(str(Path(__file__).parent / "train-ticket-trace-collect"))

class TrainTicketAnomalyDetectionController:
    """Train Ticket å¼‚å¸¸æ£€æµ‹ç³»ç»Ÿä¸»æ§åˆ¶å™¨ - ä¸€é”®å¯åŠ¨æ¨¡å¼"""
    
    def __init__(self):
        self.project_root = Path(__file__).parent
        self.config = self._load_default_config()
        self.logger = self._setup_logging()
        
        # å„ç»„ä»¶çš„çŠ¶æ€
        self.component_status = {
            "load_test": "æœªå¼€å§‹",
            "data_collection": "æœªå¼€å§‹",
            "anomaly_detection": "æœªå¼€å§‹",
            "fault_injection": "æœªå¼€å§‹"
        }
        
        # è¿è¡Œç»“æœå­˜å‚¨
        self.results = {
            "start_time": None,
            "end_time": None,
            "real_time_detections": []
        }
        
        # å®æ—¶ç›‘æ§ç›¸å…³
        self.monitoring_active = False
        self.last_processed_minute = None
        
        self.logger.info("ğŸš€ Train Ticket å¼‚å¸¸æ£€æµ‹ç³»ç»Ÿå¯åŠ¨")
        self.logger.info("ä¸€é”®å¯åŠ¨æ¨¡å¼ï¼šè‡ªåŠ¨å‹æµ‹ + æ•°æ®é‡‡é›† + å®æ—¶å¼‚å¸¸æ£€æµ‹")
        self.logger.info("æŒ‰ Ctrl+C åœæ­¢è¿è¡Œ")

    def _load_default_config(self) -> Dict:
        """åŠ è½½é»˜è®¤é…ç½®"""
        return {
            "real_time_mode": {
                "enabled": True,
                "check_interval_seconds": 30,
                "auto_process_delay_seconds": 65,
                "detection_threshold": 0.15,
                "warmup_minutes": 3  # å‹æµ‹é¢„çƒ­æ—¶é—´ï¼Œä¹‹åå¼€å§‹æ³¨å…¥æ•…éšœ
            },
            "data_collection": {
                "interval_seconds": 60,
                "lookback_period": "5m"
            },
            "scripts": {
                "load_test": "load-testing/load_test.py",
                "fault_injection": "fault-injection/fault_injector.py",
                "anomaly_detection": "anomaly-detection/vae_detector.py"
            }
        }

    def _setup_logging(self):
        """è®¾ç½®æ—¥å¿—"""
        logger = logging.getLogger('MainController')
        logger.setLevel(logging.INFO)
        
        # æ¸…é™¤ç°æœ‰å¤„ç†å™¨
        for handler in logger.handlers[:]:
            logger.removeHandler(handler)
        
        # æ§åˆ¶å°å¤„ç†å™¨
        console_handler = logging.StreamHandler()
        console_handler.setLevel(logging.INFO)
        formatter = logging.Formatter('%(asctime)s - [ä¸»æ§åˆ¶å™¨] - %(levelname)s - %(message)s')
        console_handler.setFormatter(formatter)
        logger.addHandler(console_handler)
        
        # æ–‡ä»¶å¤„ç†å™¨
        log_dir = self.project_root / "logs"
        log_dir.mkdir(exist_ok=True)
        
        file_handler = logging.FileHandler(
            log_dir / f"main_controller_{datetime.now().strftime('%Y%m%d_%H%M%S')}.log",
            encoding='utf-8'
        )
        file_handler.setLevel(logging.DEBUG)
        file_handler.setFormatter(formatter)
        logger.addHandler(file_handler)
        
        return logger

    def _run_subprocess(self, cmd: List[str], component_name: str, 
                       timeout: Optional[int] = None, 
                       background: bool = False) -> subprocess.Popen:
        """è¿è¡Œå­è¿›ç¨‹"""
        self.logger.info(f"å¯åŠ¨ {component_name}")
        
        try:
            if background:
                # åå°è¿è¡Œ
                process = subprocess.Popen(
                    cmd,
                    stdout=subprocess.PIPE,
                    stderr=subprocess.PIPE,
                    text=True,
                    cwd=self.project_root
                )
                self.component_status[component_name.lower().replace(' ', '_')] = "è¿è¡Œä¸­"
                return process
            else:
                # å‰å°è¿è¡Œå¹¶ç­‰å¾…å®Œæˆ
                result = subprocess.run(
                    cmd,
                    capture_output=True,
                    text=True,
                    timeout=timeout,
                    cwd=self.project_root
                )
                
                if result.returncode == 0:
                    self.logger.info(f"{component_name} æ‰§è¡ŒæˆåŠŸ")
                    self.component_status[component_name.lower().replace(' ', '_')] = "å®Œæˆ"
                else:
                    self.logger.error(f"{component_name} æ‰§è¡Œå¤±è´¥: {result.stderr}")
                    self.component_status[component_name.lower().replace(' ', '_')] = "å¤±è´¥"
                
                return result
                
        except subprocess.TimeoutExpired:
            self.logger.error(f"{component_name} æ‰§è¡Œè¶…æ—¶")
            self.component_status[component_name.lower().replace(' ', '_')] = "è¶…æ—¶"
        except Exception as e:
            self.logger.error(f"{component_name} æ‰§è¡Œå¼‚å¸¸: {e}")
            self.component_status[component_name.lower().replace(' ', '_')] = "å¼‚å¸¸"

    def start_load_test(self) -> Optional[subprocess.Popen]:
        """å¯åŠ¨å‹æµ‹è„šæœ¬ï¼ˆæ¨¡æ‹Ÿè°ƒç”¨ï¼‰"""
        self.logger.info("ğŸ”„ å¯åŠ¨å‹æµ‹è„šæœ¬...")
        
        # æ¨¡æ‹Ÿå¯åŠ¨å¤–éƒ¨å‹æµ‹è„šæœ¬ï¼ˆå®é™…åº”ç”¨æ—¶æ›¿æ¢ä¸ºçœŸå®è„šæœ¬è·¯å¾„ï¼‰
        script_path = self.project_root / self.config["scripts"]["load_test"]
        
        if not os.path.exists(script_path):
            # æ¨¡æ‹Ÿè„šæœ¬ä¸å­˜åœ¨æ—¶çš„å¤„ç†
            self.logger.warning(f"å‹æµ‹è„šæœ¬ä¸å­˜åœ¨: {script_path}, ä½¿ç”¨æ¨¡æ‹Ÿå®ç°")
            # ç”Ÿæˆæ¨¡æ‹Ÿè„šæœ¬è¾“å‡ºç›®å½•
            output_dir = self.project_root / "load-testing" / "output"
            output_dir.mkdir(parents=True, exist_ok=True)
            
            # å†™å…¥æ¨¡æ‹Ÿæ•°æ®
            with open(output_dir / f"loadtest_status_{datetime.now().strftime('%Y%m%d')}.txt", "w") as f:
                f.write("Load testing active\n")
                f.write(f"Start time: {datetime.now().isoformat()}\n")
                f.write("Users: 100\n")
                f.write("Requests per second: 50\n")
        
        # è¿™é‡Œæ¨¡æ‹Ÿå¯åŠ¨å‹æµ‹è„šæœ¬ï¼Œè¿”å›ä¸€ä¸ªå‡çš„è¿›ç¨‹
        # å®é™…åº”è¯¥æ˜¯ï¼šreturn self._run_subprocess([sys.executable, str(script_path)], "load_test", background=True)
        
        # å ä½ç”¨å‡è¿›ç¨‹
        cmd = [
            sys.executable, "-c", 
            """
import time
print("å‹æµ‹è„šæœ¬å¯åŠ¨")
while True:
    time.sleep(10)  # æ¨¡æ‹Ÿè¿è¡Œä¸­
            """
        ]
        
        return self._run_subprocess(cmd, "load_test", background=True)

    def start_data_collection(self, duration_minutes: int = 0) -> subprocess.Popen:
        """å¯åŠ¨æ•°æ®é‡‡é›†"""
        collector_script = self.project_root / "train-ticket-trace-collect" / "trace_collector.py"
        
        cmd = [
            sys.executable, str(collector_script),
            "--duration", str(duration_minutes)
        ]
        
        return self._run_subprocess(cmd, "data_collection", background=True)

    def start_fault_injection(self) -> Optional[subprocess.Popen]:
        """å¯åŠ¨æ•…éšœæ³¨å…¥ï¼ˆæ¨¡æ‹Ÿè°ƒç”¨å¤–éƒ¨è„šæœ¬ï¼‰"""
        self.logger.info("ğŸ’¥ å¯åŠ¨æ•…éšœæ³¨å…¥è„šæœ¬...")
        
        # æ¨¡æ‹Ÿå¯åŠ¨å¤–éƒ¨æ•…éšœæ³¨å…¥è„šæœ¬ï¼ˆå®é™…åº”ç”¨æ—¶æ›¿æ¢ä¸ºçœŸå®è„šæœ¬è·¯å¾„ï¼‰
        script_path = self.project_root / self.config["scripts"]["fault_injection"]
        
        if not os.path.exists(script_path):
            # æ¨¡æ‹Ÿè„šæœ¬ä¸å­˜åœ¨æ—¶ç”Ÿæˆè®°å½•
            self.logger.warning(f"æ•…éšœæ³¨å…¥è„šæœ¬ä¸å­˜åœ¨: {script_path}, ä½¿ç”¨æ¨¡æ‹Ÿå®ç°")
            # åˆ›å»ºè®°å½•ç›®å½•
            record_dir = self.project_root / "fault_injection_records"
            record_dir.mkdir(exist_ok=True)
            
            # å†™å…¥æ¨¡æ‹Ÿçš„æ•…éšœè®°å½•
            self._generate_mock_fault_records()
        
        # è¿™é‡Œæ¨¡æ‹Ÿå¯åŠ¨æ•…éšœæ³¨å…¥è„šæœ¬ï¼Œè¿”å›ä¸€ä¸ªå‡çš„è¿›ç¨‹
        # å®é™…åº”è¯¥æ˜¯ï¼šreturn self._run_subprocess([sys.executable, str(script_path)], "fault_injection", background=True)
        
        # å ä½ç”¨å‡è¿›ç¨‹
        cmd = [
            sys.executable, "-c", 
            """
import time
print("æ•…éšœæ³¨å…¥è„šæœ¬å¯åŠ¨")
while True:
    time.sleep(10)  # æ¨¡æ‹Ÿè¿è¡Œä¸­
            """
        ]
        
        return self._run_subprocess(cmd, "fault_injection", background=True)

    def check_for_new_data(self, target_date: str = None) -> List[str]:
        """æ£€æŸ¥æ˜¯å¦æœ‰æ–°çš„åˆ†é’Ÿçº§æ•°æ®æ–‡ä»¶"""
        target_date = target_date or datetime.now().strftime("%Y-%m-%d")
        trace_dir = self.project_root / "trace" / target_date / "csv"  # ä¿®æ”¹ä¸ºtraceç›®å½•
        
        if not trace_dir.exists():
            return []
        
        # è·å–æ‰€æœ‰CSVæ–‡ä»¶
        csv_files = list(trace_dir.glob("*.csv"))
        new_files = []
        
        current_time = datetime.now()
        
        for csv_file in csv_files:
            # æ£€æŸ¥æ˜¯å¦å·²æœ‰å¯¹åº”çš„.graph_processedæ ‡å¿—æ–‡ä»¶
            flag_file = str(csv_file).replace('.csv', '.graph_processed')
            
            if os.path.exists(flag_file):
                continue  # å·²ç»å¤„ç†è¿‡ï¼Œè·³è¿‡
            
            # è§£ææ–‡ä»¶å (æ ¼å¼: HH_MM.csv)
            try:
                filename = csv_file.stem
                hour, minute = filename.split('_')
                file_time = datetime.now().replace(hour=int(hour), minute=int(minute), second=0, microsecond=0)
                
                # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å·²ç»"æˆç†Ÿ"ï¼ˆè¶…è¿‡65ç§’ï¼‰
                time_diff = (current_time - file_time).total_seconds()
                
                if time_diff >= self.config["real_time_mode"]["auto_process_delay_seconds"]:
                    new_files.append(str(csv_file))
                        
            except ValueError:
                continue
        
        return new_files

    def process_collected_data(self, csv_file_path: str = None, target_date: str = None):
        """å¤„ç†é‡‡é›†çš„æ•°æ®ï¼ˆå›¾åˆ†æï¼‰"""
        processor_script = self.project_root / "train-ticket-trace-collect" / "graph_post_processor.py"
        
        if csv_file_path:
            # å¤„ç†ç‰¹å®šæ–‡ä»¶
            cmd = [sys.executable, str(processor_script), "--file", csv_file_path]
        else:
            # å¤„ç†æ•´ä¸ªæ—¥æœŸ
            cmd = [sys.executable, str(processor_script)]
            if target_date:
                cmd.extend(["--date", target_date])
        
        self._run_subprocess(cmd, "graph_processing", timeout=300)  # é™ä½è¶…æ—¶æ—¶é—´

    def _generate_mock_fault_records(self):
        """ç”Ÿæˆæ¨¡æ‹Ÿçš„æ•…éšœæ³¨å…¥è®°å½•æ–‡ä»¶ï¼ˆæ¨¡æ‹Ÿå¤–éƒ¨æ³¨å…¥è„šæœ¬çš„è¡Œä¸ºï¼‰"""
        record_dir = self.project_root / "fault_injection_records"
        today = datetime.now().strftime("%Y-%m-%d")
        record_file = record_dir / f"fault_records_{today}.json"
        
        # å¦‚æœå·²ç»å­˜åœ¨ï¼Œå°±ä¸é‡å¤ç”Ÿæˆ
        if record_file.exists():
            return
        
        # ç”Ÿæˆè‹¥å¹²ä¸ªé—´éš”çš„æ•…éšœè®°å½•
        current_time = datetime.now()
        records = []
        
        # æ¨¡æ‹Ÿæ¯10åˆ†é’Ÿäº§ç”Ÿä¸€æ¬¡æ•…éšœï¼ŒæŒç»­5åˆ†é’Ÿ
        for i in range(6):  # 6ä¸ªå‘¨æœŸï¼Œå…±60åˆ†é’Ÿ
            # æ•…éšœå¼€å§‹æ—¶é—´ï¼šå½“å‰æ—¶é—´ + é¢„çƒ­æ—¶é—´ + i*10åˆ†é’Ÿ
            fault_time = current_time + timedelta(minutes=self.config["real_time_mode"]["warmup_minutes"] + i*10)
            
            # æ•…éšœè®°å½•
            for j in range(5):  # æ¯æ¬¡æ•…éšœæŒç»­5åˆ†é’Ÿ
                minute_time = fault_time + timedelta(minutes=j)
                
                # éšæœºé€‰æ‹©æ•…éšœç±»å‹
                fault_types = [
                    {"type": "high_latency", "description": "é«˜å»¶è¿Ÿæ•…éšœ", "intensity": "medium"},
                    {"type": "error_injection", "description": "é”™è¯¯æ³¨å…¥æ•…éšœ", "intensity": "high"},
                    {"type": "service_unavailable", "description": "æœåŠ¡ä¸å¯ç”¨æ•…éšœ", "intensity": "high"},
                    {"type": "network_delay", "description": "ç½‘ç»œå»¶è¿Ÿæ•…éšœ", "intensity": "low"}
                ]
                
                import random
                fault_type = random.choice(fault_types)
                
                record = {
                    "timestamp": minute_time.isoformat(),
                    "minute_key": minute_time.strftime("%H_%M"),
                    "date": today,
                    "fault_type": fault_type["type"],
                    "description": fault_type["description"],
                    "intensity": fault_type["intensity"],
                    "expected_anomaly": True
                }
                
                records.append(record)
            
            # æ•…éšœé—´æ­‡æœŸï¼ˆ5åˆ†é’Ÿï¼‰
            for j in range(5):
                minute_time = fault_time + timedelta(minutes=j+5)
                
                record = {
                    "timestamp": minute_time.isoformat(),
                    "minute_key": minute_time.strftime("%H_%M"),
                    "date": today,
                    "fault_type": "normal",
                    "description": "ç³»ç»Ÿæ­£å¸¸è¿è¡Œ",
                    "intensity": "none",
                    "expected_anomaly": False
                }
                
                records.append(record)
        
        # ä¿å­˜æ•…éšœè®°å½•æ–‡ä»¶
        with open(record_file, 'w', encoding='utf-8') as f:
            json.dump(records, f, indent=2, ensure_ascii=False)
        
        self.logger.info(f"å·²ç”Ÿæˆæ¨¡æ‹Ÿæ•…éšœè®°å½•: {record_file}")
        self.logger.info(f"å…± {len(records)} æ¡è®°å½•ï¼ŒåŒ…æ‹¬æ•…éšœæœŸå’Œæ­£å¸¸æœŸ")

    def process_new_files_real_time(self, csv_files: List[str]) -> bool:
        """å®æ—¶å¤„ç†æ–°çš„CSVæ–‡ä»¶"""
        if not csv_files:
            return False
        
        self.logger.info(f"ğŸ“‹ å‘ç° {len(csv_files)} ä¸ªæ–°çš„æ•°æ®æ–‡ä»¶ï¼Œå¼€å§‹å®æ—¶å¤„ç†...")
        
        # å¯¹æ¯ä¸ªæ–°æ–‡ä»¶è¿›è¡Œå›¾åˆ†æå’Œå¼‚å¸¸æ£€æµ‹
        for csv_file in csv_files:
            try:
                # å…ˆè¿›è¡Œå›¾åˆ†æå¤„ç†
                self.logger.info(f"ğŸ”§ å¯¹æ–‡ä»¶è¿›è¡Œå›¾åˆ†æ: {os.path.basename(csv_file)}")
                self.process_collected_data(csv_file_path=csv_file)
                
                # æ£€æŸ¥æ˜¯å¦ç”Ÿæˆäº†å¤„ç†æ ‡å¿—
                flag_file = csv_file.replace('.csv', '.graph_processed')
                if not os.path.exists(flag_file):
                    self.logger.warning(f"å›¾åˆ†æå¯èƒ½å¤±è´¥ï¼Œæœªæ‰¾åˆ°æ ‡å¿—æ–‡ä»¶: {os.path.basename(flag_file)}")
                    continue
                
                # è°ƒç”¨å¼‚å¸¸æ£€æµ‹
                detection_result = self.run_anomaly_detection(csv_file)
                
                # éªŒè¯ç»“æœ
                validation = self.validate_detection_result(detection_result)
                
                # æŠ¥å‘Šæ£€æµ‹ç»“æœ
                self.report_anomaly_detection(csv_file, detection_result, validation)
                
            except Exception as e:
                self.logger.error(f"âŒ å¤„ç†æ–‡ä»¶ {csv_file} æ—¶å‡ºé”™: {e}")
        
        return True

    def run_anomaly_detection(self, csv_file: str) -> Dict:
        """è°ƒç”¨å¼‚å¸¸æ£€æµ‹è„šæœ¬ï¼ˆæ¨¡æ‹Ÿï¼‰"""
        self.logger.info(f"ğŸ” å¯¹æ–‡ä»¶è¿è¡Œå¼‚å¸¸æ£€æµ‹: {os.path.basename(csv_file)}")
        
        # æ¨¡æ‹Ÿå¯åŠ¨å¤–éƒ¨å¼‚å¸¸æ£€æµ‹è„šæœ¬ï¼ˆå®é™…åº”ç”¨æ—¶æ›¿æ¢ä¸ºçœŸå®è„šæœ¬è·¯å¾„ï¼‰
        script_path = self.project_root / self.config["scripts"]["anomaly_detection"]
        
        if not os.path.exists(script_path):
            self.logger.warning(f"å¼‚å¸¸æ£€æµ‹è„šæœ¬ä¸å­˜åœ¨: {script_path}, ä½¿ç”¨æ¨¡æ‹Ÿå®ç°")
        
        # è¿™é‡Œæ¨¡æ‹Ÿå¼‚å¸¸æ£€æµ‹ç»“æœï¼Œå®é™…åº”è¯¥è°ƒç”¨VAEè„šæœ¬
        # å®é™…åº”è¯¥æ˜¯ï¼š
        # result = self._run_subprocess([sys.executable, str(script_path), "--file", csv_file], "anomaly_detection")
        # ç„¶åè§£æresult.stdoutè·å–ç»“æœ
        
        # è¯»å–æ–‡ä»¶åŸºæœ¬ä¿¡æ¯ï¼ˆå‡è£…æˆ‘ä»¬åˆ†æäº†å®ƒï¼‰
        import pandas as pd
        try:
            df = pd.read_csv(csv_file)
            trace_count = len(df['traceIdLow'].unique()) if 'traceIdLow' in df.columns else 0
            span_count = len(df)
        except Exception as e:
            self.logger.error(f"è¯»å–CSVæ–‡ä»¶å¤±è´¥: {e}")
            trace_count = 0
            span_count = 0
        
        # æ¨¡æ‹Ÿå¼‚å¸¸æ£€æµ‹ç»“æœ
        import random
        anomaly_score = random.uniform(0.0, 1.0)
        threshold = self.config["real_time_mode"]["detection_threshold"]
        is_anomaly = anomaly_score > threshold
        
        result = {
            "file_name": os.path.basename(csv_file),
            "analysis_time": datetime.now().isoformat(),
            "trace_count": trace_count, 
            "span_count": span_count,
            "anomaly_score": round(anomaly_score, 4),
            "threshold": threshold,
            "anomaly_detected": is_anomaly,
            "anomaly_types": []
        }
        
        if is_anomaly:
            # éšæœºç”Ÿæˆå¼‚å¸¸ç±»å‹
            possible_anomalies = ["high_latency", "error_spike", "unusual_pattern", "service_degradation"]
            result["anomaly_types"] = random.sample(possible_anomalies, random.randint(1, 2))
        
        # ç”Ÿæˆå¼‚å¸¸æ£€æµ‹è¾“å‡ºç›®å½•
        output_dir = self.project_root / "anomaly_detection" / "output"
        output_dir.mkdir(parents=True, exist_ok=True)
        
        # å°†ç»“æœä¿å­˜ä¸ºJSONæ–‡ä»¶ï¼ˆæ¨¡æ‹Ÿå¼‚å¸¸æ£€æµ‹è„šæœ¬çš„è¾“å‡ºï¼‰
        result_file = output_dir / f"detection_{os.path.basename(csv_file).replace('.csv', '')}.json"
        with open(result_file, "w", encoding="utf-8") as f:
            json.dump(result, f, indent=2, ensure_ascii=False)
            
        return result

    def load_fault_injection_records(self, target_date: str = None) -> List[Dict]:
        """åŠ è½½æ•…éšœæ³¨å…¥è®°å½•"""
        target_date = target_date or datetime.now().strftime("%Y-%m-%d")
        fault_record_dir = self.project_root / "fault_injection_records"
        record_file = fault_record_dir / f"fault_records_{target_date}.json"
        
        if not record_file.exists():
            return []
        
        try:
            with open(record_file, 'r', encoding='utf-8') as f:
                return json.load(f)
        except Exception as e:
            self.logger.error(f"åŠ è½½æ•…éšœè®°å½•å¤±è´¥: {e}")
            return []

    def validate_detection_result(self, detection_result: Dict) -> Dict:
        """éªŒè¯æ£€æµ‹ç»“æœä¸æ•…éšœæ³¨å…¥è®°å½•çš„åŒ¹é…åº¦"""
        file_name = detection_result.get("file_name", "")
        if not file_name.endswith(".csv"):
            return {"validation": "skipped", "reason": "invalid_filename"}
        
        # ä»æ–‡ä»¶åæå–æ—¶é—´ (HH_MM.csv)
        try:
            minute_key = file_name.replace(".csv", "")
            target_date = datetime.now().strftime("%Y-%m-%d")
        except:
            return {"validation": "failed", "reason": "filename_parse_error"}
        
        # åŠ è½½æ•…éšœè®°å½•
        fault_records = self.load_fault_injection_records(target_date)
        
        # æŸ¥æ‰¾å¯¹åº”æ—¶é—´çš„æ•…éšœè®°å½•
        matching_record = None
        for record in fault_records:
            if record.get("minute_key") == minute_key:
                matching_record = record
                break
        
        if not matching_record:
            return {
                "validation": "no_fault_record",
                "reason": f"æœªæ‰¾åˆ°æ—¶é—´ {minute_key} çš„æ•…éšœè®°å½•"
            }
        
        # éªŒè¯æ£€æµ‹ç»“æœ
        expected_anomaly = matching_record.get("expected_anomaly", False)
        detected_anomaly = detection_result.get("anomaly_detected", False)
        
        validation_result = {
            "validation": "completed",
            "minute_key": minute_key,
            "expected_anomaly": expected_anomaly,
            "detected_anomaly": detected_anomaly,
            "fault_info": {
                "type": matching_record.get("fault_type"),
                "description": matching_record.get("description"),
                "intensity": matching_record.get("intensity")
            }
        }
        
        # åˆ¤æ–­æ£€æµ‹å‡†ç¡®æ€§
        if expected_anomaly == detected_anomaly:
            if expected_anomaly:
                validation_result["accuracy"] = "true_positive"  # æ­£ç¡®æ£€æµ‹åˆ°å¼‚å¸¸
                validation_result["result"] = "âœ… æ­£ç¡®æ£€æµ‹"
            else:
                validation_result["accuracy"] = "true_negative"  # æ­£ç¡®è¯†åˆ«æ­£å¸¸
                validation_result["result"] = "âœ… æ­£ç¡®è¯†åˆ«"
        else:
            if expected_anomaly and not detected_anomaly:
                validation_result["accuracy"] = "false_negative"  # æ¼æŠ¥
                validation_result["result"] = "âŒ æ¼æŠ¥å¼‚å¸¸"
            else:
                validation_result["accuracy"] = "false_positive"  # è¯¯æŠ¥
                validation_result["result"] = "âŒ è¯¯æŠ¥å¼‚å¸¸"
        
        return validation_result
    
    def report_anomaly_detection(self, csv_file: str, detection_result: Dict, validation: Dict):
        """æŠ¥å‘Šå¼‚å¸¸æ£€æµ‹ç»“æœ"""
        if detection_result.get("anomaly_detected", False):
            self.logger.warning("ğŸš¨ ================================")
            self.logger.warning("ğŸš¨ æ£€æµ‹åˆ°å®æ—¶å¼‚å¸¸ï¼")
            self.logger.warning("ğŸš¨ ================================")
            self.logger.warning(f"ğŸ“ æ–‡ä»¶: {detection_result['file_name']}")
            self.logger.warning(f"âš ï¸  å¼‚å¸¸åˆ†æ•°: {detection_result['anomaly_score']} (é˜ˆå€¼: {detection_result['threshold']})")
            self.logger.warning(f"ğŸ·ï¸  å¼‚å¸¸ç±»å‹: {', '.join(detection_result.get('anomaly_types', []))}")
            self.logger.warning(f"ğŸ“Š Traceæ•°é‡: {detection_result['trace_count']}")
            self.logger.warning(f"ğŸ“ˆ Spanæ•°é‡: {detection_result['span_count']}")
            
            # æ˜¾ç¤ºéªŒè¯ç»“æœ
            if validation.get("validation") == "completed":
                self.logger.warning(f"ğŸ” éªŒè¯ç»“æœ: {validation.get('result', 'æœªçŸ¥')}")
                self.logger.warning(f"ğŸ“‹ æ•…éšœç±»å‹: {validation.get('fault_info', {}).get('description', 'æœªçŸ¥')}")
                self.logger.warning(f"ğŸ¯ å‡†ç¡®æ€§: {validation.get('accuracy', 'æœªçŸ¥')}")
            
            self.logger.warning("ğŸš¨ ================================")
        else:
            # æ˜¾ç¤ºæ­£å¸¸æ£€æµ‹ç»“æœçš„éªŒè¯
            if validation.get("validation") == "completed":
                result_emoji = "âœ…" if validation.get("accuracy") in ["true_negative", "true_positive"] else "âŒ"
                self.logger.info(f"{result_emoji} {os.path.basename(csv_file)} - æ­£å¸¸ ({validation.get('result', 'æœªéªŒè¯')})")
            else:
                self.logger.info(f"âœ… {os.path.basename(csv_file)} - æ­£å¸¸")

        # ä¿å­˜åˆ°ç»“æœåˆ—è¡¨
        self.results["real_time_detections"].append({
            "timestamp": datetime.now().isoformat(),
            "file": os.path.basename(csv_file),
            "result": detection_result,
            "validation": validation
        })

    def process_new_files_real_time(self, csv_files: List[str]) -> bool:
        """å®æ—¶å¤„ç†æ–°çš„CSVæ–‡ä»¶"""
        if not csv_files:
            return False
        
        self.logger.info(f"ğŸ“‹ å‘ç° {len(csv_files)} ä¸ªæ–°çš„æ•°æ®æ–‡ä»¶ï¼Œå¼€å§‹å®æ—¶å¤„ç†...")
        
        # è·å–æ—¥æœŸ
        target_date = datetime.now().strftime("%Y-%m-%d")
        date_dir = self.project_root / "trace_output" / target_date
        
        # æ£€æŸ¥æ˜¯å¦éœ€è¦å›¾åˆ†æå¤„ç†
        graph_flag = date_dir / ".graph_processed"
        need_graph_processing = not graph_flag.exists()
        
        if need_graph_processing:
            self.logger.info("ğŸ”§ é¦–æ¬¡å¤„ç†ï¼Œæ‰§è¡Œå›¾åˆ†æ...")
            self.process_collected_data(target_date)
        
        # å¯¹æ¯ä¸ªæ–°æ–‡ä»¶è¿›è¡Œå¼‚å¸¸æ£€æµ‹
        for csv_file in csv_files:
            try:
                # è°ƒç”¨å¼‚å¸¸æ£€æµ‹ï¼ˆæ¨¡æ‹Ÿï¼‰
                detection_result = self.run_anomaly_detection(csv_file)
                
                # éªŒè¯ç»“æœ
                validation = self.validate_detection_result(detection_result)
                
                # æŠ¥å‘Šæ£€æµ‹ç»“æœ
                self.report_anomaly_detection(csv_file, detection_result, validation)
                
            except Exception as e:
                self.logger.error(f"âŒ å¤„ç†æ–‡ä»¶ {csv_file} æ—¶å‡ºé”™: {e}")
        
        return True

    def run_real_time_monitoring(self):
        """è¿è¡Œå®æ—¶ç›‘æ§æ¨¡å¼"""
        self.logger.info("ğŸš€ å¯åŠ¨å®æ—¶å¼‚å¸¸æ£€æµ‹ç›‘æ§ç³»ç»Ÿ")
        self.logger.info("ğŸ“Š ç³»ç»Ÿå°†è‡ªåŠ¨ï¼š")
        self.logger.info("   1. å¯åŠ¨å‹æµ‹")
        self.logger.info("   2. å¼€å§‹æ•°æ®é‡‡é›†")
        self.logger.info(f"   3. {self.config['real_time_mode']['warmup_minutes']}åˆ†é’Ÿåè‡ªåŠ¨å¯åŠ¨æ•…éšœæ³¨å…¥")
        self.logger.info("   4. å®æ—¶å¼‚å¸¸æ£€æµ‹")
        self.logger.info("   5. æ£€æµ‹ç»“æœéªŒè¯")
        self.logger.info("ğŸ›‘ æŒ‰ Ctrl+C åœæ­¢è¿è¡Œ")
        
        self.monitoring_active = True
        self.results["start_time"] = datetime.now().isoformat()
        
        # å¯åŠ¨å‹æµ‹
        self.logger.info("ğŸ”„ å¯åŠ¨å‹æµ‹...")
        load_test_process = self.start_load_test()
        
        # å¯åŠ¨æ•°æ®é‡‡é›†
        self.logger.info("ğŸ“¡ å¯åŠ¨æ•°æ®é‡‡é›†...")
        collection_process = self.start_data_collection(duration_minutes=0)  # æŒç»­è¿è¡Œ
        
        # ç­‰å¾…é¢„çƒ­æœŸç»“æŸ
        warmup_minutes = self.config["real_time_mode"]["warmup_minutes"]
        self.logger.info(f"â³ ç­‰å¾… {warmup_minutes} åˆ†é’Ÿé¢„çƒ­æœŸ...")
        
        # é¢„çƒ­æœŸåå†å¯åŠ¨æ•…éšœæ³¨å…¥
        fault_injection_process = None
        
        # å¯åŠ¨ç›‘æ§å¾ªç¯
        check_interval = self.config["real_time_mode"]["check_interval_seconds"]
        self.logger.info(f"ğŸ” å¼€å§‹å®æ—¶ç›‘æ§ (æ¯{check_interval}ç§’æ£€æŸ¥ä¸€æ¬¡æ–°æ•°æ®)")
        
        start_time = time.time()
        try:
            while self.monitoring_active:
                elapsed_minutes = (time.time() - start_time) / 60
                
                # åˆ°è¾¾é¢„çƒ­æ—¶é—´åï¼Œå¯åŠ¨æ•…éšœæ³¨å…¥
                if elapsed_minutes >= warmup_minutes and fault_injection_process is None:
                    self.logger.info(f"ğŸ”¥ é¢„çƒ­æœŸç»“æŸï¼Œå¯åŠ¨æ•…éšœæ³¨å…¥...")
                    fault_injection_process = self.start_fault_injection()
                    self.component_status["fault_injection"] = "è¿è¡Œä¸­"
                
                # æ£€æŸ¥æ–°æ•°æ®
                new_files = self.check_for_new_data()
                
                if new_files:
                    self.process_new_files_real_time(new_files)
                
                # æ˜¾ç¤ºè¿è¡ŒçŠ¶æ€
                elapsed_hours = elapsed_minutes / 60
                detection_count = len(self.results["real_time_detections"])
                anomaly_count = len([d for d in self.results["real_time_detections"] if d["result"].get("anomaly_detected", False)])
                
                # è®¡ç®—éªŒè¯ç»Ÿè®¡
                validated_detections = [d for d in self.results["real_time_detections"] 
                                      if d["validation"].get("validation") == "completed"]
                accuracy_stats = {"true_positive": 0, "true_negative": 0, "false_positive": 0, "false_negative": 0}
                
                for detection in validated_detections:
                    accuracy = detection["validation"].get("accuracy", "unknown")
                    if accuracy in accuracy_stats:
                        accuracy_stats[accuracy] += 1
                
                total_validated = sum(accuracy_stats.values())
                accuracy_rate = ((accuracy_stats["true_positive"] + accuracy_stats["true_negative"]) / max(total_validated, 1)) * 100
                
                self.logger.info(f"ğŸ“ˆ ç›‘æ§çŠ¶æ€: è¿è¡Œ{elapsed_hours:.1f}å°æ—¶ | æ£€æµ‹{detection_count}æ¬¡ | å¼‚å¸¸{anomaly_count}æ¬¡ | å‡†ç¡®ç‡{accuracy_rate:.1f}%")
                
                # ç­‰å¾…ä¸‹æ¬¡æ£€æŸ¥
                time.sleep(check_interval)
                
        except KeyboardInterrupt:
            self.logger.info("ğŸ›‘ ç”¨æˆ·ä¸­æ–­ç›‘æ§")
        finally:
            self.monitoring_active = False
            
            # åœæ­¢æ‰€æœ‰åå°è¿›ç¨‹
            if load_test_process:
                self.logger.info("ğŸ›‘ åœæ­¢å‹æµ‹...")
                load_test_process.terminate()
                try:
                    load_test_process.wait(timeout=30)
                except subprocess.TimeoutExpired:
                    load_test_process.kill()
            
            if collection_process:
                self.logger.info("ğŸ›‘ åœæ­¢æ•°æ®é‡‡é›†...")
                collection_process.terminate()
                try:
                    collection_process.wait(timeout=30)
                except subprocess.TimeoutExpired:
                    collection_process.kill()
            
            if fault_injection_process:
                self.logger.info("ğŸ›‘ åœæ­¢æ•…éšœæ³¨å…¥...")
                fault_injection_process.terminate()
                try:
                    fault_injection_process.wait(timeout=30)
                except subprocess.TimeoutExpired:
                    fault_injection_process.kill()
            
            self.results["end_time"] = datetime.now().isoformat()
            self.generate_final_report()

    def generate_final_report(self):
        """ç”Ÿæˆæœ€ç»ˆæŠ¥å‘Š"""
        report_dir = self.project_root / "experiment_reports"
        report_dir.mkdir(exist_ok=True)
        
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        report_file = report_dir / f"experiment_report_{timestamp}.json"
        
        detection_count = len(self.results["real_time_detections"])
        anomaly_count = len([d for d in self.results["real_time_detections"] if d["result"].get("anomaly_detected", False)])
        
        # è®¡ç®—éªŒè¯ç»Ÿè®¡
        validated_detections = [d for d in self.results["real_time_detections"] 
                              if d["validation"].get("validation") == "completed"]
        
        accuracy_stats = {"true_positive": 0, "true_negative": 0, "false_positive": 0, "false_negative": 0}
        for detection in validated_detections:
            accuracy = detection["validation"].get("accuracy", "unknown")
            if accuracy in accuracy_stats:
                accuracy_stats[accuracy] += 1
        
        total_validated = sum(accuracy_stats.values())
        accuracy_rate = ((accuracy_stats["true_positive"] + accuracy_stats["true_negative"]) / max(total_validated, 1)) * 100
        
        # ç”Ÿæˆå®Œæ•´æŠ¥å‘Š
        full_report = {
            "experiment_info": {
                "start_time": self.results["start_time"],
                "end_time": self.results["end_time"],
                "duration_minutes": self._calculate_duration_minutes(),
                "warmup_minutes": self.config["real_time_mode"]["warmup_minutes"],
                "config": self.config
            },
            "component_status": self.component_status,
            "detection_summary": {
                "total": detection_count,
                "anomalies": anomaly_count,
                "anomaly_rate": (anomaly_count / max(detection_count, 1)) * 100,
                "accuracy_rate": accuracy_rate,
                "true_positive": accuracy_stats["true_positive"],
                "true_negative": accuracy_stats["true_negative"],
                "false_positive": accuracy_stats["false_positive"],
                "false_negative": accuracy_stats["false_negative"]
            },
            "detections": self.results["real_time_detections"]
        }
        
        # ä¿å­˜å®Œæ•´æŠ¥å‘Š
        with open(report_file, "w", encoding="utf-8") as f:
            json.dump(full_report, f, indent=2, ensure_ascii=False)
        
        # ç”Ÿæˆç®€åŒ–æ‘˜è¦
        summary_file = report_dir / f"experiment_summary_{timestamp}.txt"
        with open(summary_file, 'w', encoding='utf-8') as f:
            f.write("=" * 60 + "\n")
            f.write("Train Ticket å¼‚å¸¸æ£€æµ‹å®éªŒæŠ¥å‘Š\n")
            f.write("=" * 60 + "\n\n")
            f.write(f"å®éªŒæ—¶é—´: {self.results['start_time']} ~ {self.results['end_time']}\n")
            f.write(f"æ€»æ—¶é•¿: {self._calculate_duration_minutes()/60:.1f} å°æ—¶\n")
            f.write(f"é¢„çƒ­æ—¶é•¿: {self.config['real_time_mode']['warmup_minutes']} åˆ†é’Ÿ\n\n")
            
            f.write("ç»„ä»¶çŠ¶æ€:\n")
            for component, status in self.component_status.items():
                f.write(f"  {component}: {status}\n")
            f.write("\n")
            
            f.write("æ£€æµ‹ç»Ÿè®¡:\n")
            f.write(f"  æ€»æ£€æµ‹æ¬¡æ•°: {detection_count}\n")
            f.write(f"  å¼‚å¸¸æ£€æµ‹æ•°: {anomaly_count}\n")
            f.write(f"  å¼‚å¸¸ç‡: {(anomaly_count / max(detection_count, 1)) * 100:.1f}%\n")
            f.write(f"  æ£€æµ‹å‡†ç¡®ç‡: {accuracy_rate:.1f}%\n\n")
            
            f.write("å‡†ç¡®æ€§åˆ†æ:\n")
            f.write(f"  æ­£ç¡®æ£€æµ‹å¼‚å¸¸(TP): {accuracy_stats['true_positive']}\n")
            f.write(f"  æ­£ç¡®è¯†åˆ«æ­£å¸¸(TN): {accuracy_stats['true_negative']}\n") 
            f.write(f"  è¯¯æŠ¥å¼‚å¸¸(FP): {accuracy_stats['false_positive']}\n")
            f.write(f"  æ¼æŠ¥å¼‚å¸¸(FN): {accuracy_stats['false_negative']}\n")
        
        self.logger.info("ğŸ“‹ ====== å®éªŒå®Œæˆ ======")
        self.logger.info(f"ğŸ“Š æ€»è®¡æ£€æµ‹: {detection_count} æ¬¡")
        self.logger.info(f"ğŸš¨ å‘ç°å¼‚å¸¸: {anomaly_count} æ¬¡") 
        self.logger.info(f"ğŸ¯ æ£€æµ‹å‡†ç¡®ç‡: {accuracy_rate:.1f}%")
        self.logger.info(f"ğŸ“ å®Œæ•´æŠ¥å‘Š: {report_file}")
        self.logger.info(f"ğŸ“„ æ‘˜è¦æŠ¥å‘Š: {summary_file}")
        self.logger.info("ğŸ“‹ ========================")

    def _calculate_duration_minutes(self) -> float:
        """è®¡ç®—è¿è¡Œæ€»æ—¶é•¿"""
        if self.results["start_time"] and self.results["end_time"]:
            start = datetime.fromisoformat(self.results["start_time"])
            end = datetime.fromisoformat(self.results["end_time"])
            return (end - start).total_seconds() / 60
        return 0

def main():
    """ä¸»å‡½æ•° - ä¸€é”®å¯åŠ¨"""
    print("=" * 60)
    print("ğŸš€ Train Ticket å¼‚å¸¸æ£€æµ‹ç³»ç»Ÿ")
    print("=" * 60)
    print("ä¸€é”®å¯åŠ¨æ¨¡å¼ï¼šè‡ªåŠ¨è¿è¡Œæ‰€æœ‰ç»„ä»¶")
    print("åŠŸèƒ½åŒ…æ‹¬ï¼šå‹æµ‹ + æ•°æ®é‡‡é›† + æ•…éšœæ³¨å…¥ + å®æ—¶å¼‚å¸¸æ£€æµ‹")
    print("æŒ‰ Ctrl+C å¯éšæ—¶åœæ­¢")
    print("=" * 60)
    
    try:
        controller = TrainTicketAnomalyDetectionController()
        controller.run_real_time_monitoring()
        return 0
        
    except KeyboardInterrupt:
        print("\nğŸ›‘ ç³»ç»Ÿå·²åœæ­¢")
        return 0
    except Exception as e:
        print(f"âŒ ç³»ç»Ÿè¿è¡Œå¤±è´¥: {e}")
        return 1

if __name__ == "__main__":
    sys.exit(main())